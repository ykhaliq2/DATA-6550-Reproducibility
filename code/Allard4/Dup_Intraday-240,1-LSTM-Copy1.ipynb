{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bb3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from Statistics import Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c4d11a6-3ab9-493e-b2b1-f549a2c9011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.16.0rc0 # Using a old version of Tensorflow since CuDNNLSTM has been deprecated \n",
    "# Attempted to install an older version of tensorflow in order to keep CuDNNLSTM in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c387de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dropout,Dense,Input,add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c62e62",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "SEED = 9\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a826477",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_df = pd.read_csv('data/SPXconst.csv')\n",
    "all_companies = list(set(SP500_df.values.flatten()))\n",
    "all_companies.remove(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents = {'-'.join(col.split('/')[::-1]):set(SP500_df[col].dropna()) \n",
    "                for col in SP500_df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e333065e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "constituents_train = {} \n",
    "for test_year in range(1993,2016):\n",
    "    months = [str(t)+'-0'+str(m) if m<10 else str(t)+'-'+str(m) \n",
    "              for t in range(test_year-3,test_year) for m in range(1,13)]\n",
    "    constituents_train[test_year] = [list(constituents[m]) for m in months]\n",
    "    constituents_train[test_year] = set([i for sublist in constituents_train[test_year] \n",
    "                                         for i in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1545a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLSTM():\n",
    "    inputs = Input(shape=(240,1))\n",
    "    x = LSTM(units=128, return_sequences=True, activation='tanh', recurrent_activation='sigmoid')(inputs) # AI reccommended settings to\n",
    "    x = Dropout(0.1)(x)                                                                               # most closely immulate CuDNNLSTM\n",
    "    outputs = Dense(2,activation='softmax')(x)                                                        # (inputs) added to complete the tensor\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(),\n",
    "                          metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a83562c9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def callbacks_req(model_type='LSTM'):\n",
    "    csv_logger = CSVLogger(model_folder+'/training-log-'+model_type+'-'+str(test_year)+'.csv')\n",
    "    filepath = model_folder+\"/model-\" + model_type + '-' + str(test_year) + \"-E{epoch:02d}.h5\"\n",
    "    model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss',save_best_only=False, save_freq='epoch') # period=1 changed to save_freq='epoch'\n",
    "    earlyStopping = EarlyStopping(monitor='val_loss',mode='min',patience=10,restore_best_weights=True)\n",
    "    return [csv_logger,earlyStopping,model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98cfd453",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def reshaper(arr):\n",
    "    arr = np.array(np.split(arr,3,axis=1))\n",
    "    arr = np.swapaxes(arr,0,1)\n",
    "    arr = np.swapaxes(arr,1,2)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27934d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def trainer(train_data,test_data,model_type='LSTM'):\n",
    "    np.random.shuffle(train_data)\n",
    "    train_x,train_y,train_ret = train_data[:,2:-2],train_data[:,-1],train_data[:,-2]\n",
    "    train_x = np.reshape(train_x,(len(train_x),240,1))\n",
    "    train_y = np.reshape(train_y,(-1, 1))\n",
    "    train_ret = np.reshape(train_ret,(-1, 1))\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(train_y)\n",
    "    enc_y = enc.transform(train_y).toarray()\n",
    "    train_ret = np.hstack((np.zeros((len(train_data),1)),train_ret)) \n",
    "\n",
    "    if model_type == 'LSTM':\n",
    "        model = makeLSTM()\n",
    "    else:\n",
    "        return\n",
    "    callbacks = callbacks_req(model_type)\n",
    "    \n",
    "    model.fit(train_x,\n",
    "              enc_y,\n",
    "              epochs=1000,\n",
    "              validation_split=0.2,\n",
    "              callbacks=callbacks,\n",
    "              batch_size=512\n",
    "              )\n",
    "\n",
    "    dates = list(set(test_data[:,0]))\n",
    "    predictions = {}\n",
    "    for day in dates:\n",
    "        test_d = test_data[test_data[:,0]==day]\n",
    "        test_d = np.reshape(test_d[:,2:-2], (len(test_d),240,1))\n",
    "        predictions[day] = model.predict(test_d)[:,1]\n",
    "    return model,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee8629a2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def trained(filename,train_data,test_data):\n",
    "    model = load_model(filename)\n",
    "\n",
    "    dates = list(set(test_data[:,0]))\n",
    "    predictions = {}\n",
    "    for day in dates:\n",
    "        test_d = test_data[test_data[:,0]==day]\n",
    "        test_d = np.reshape(test_d[:,2:-2],(len(test_d),240,1))\n",
    "        predictions[day] = model.predict(test_d)[:,1]\n",
    "    return model,predictions     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c93dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(test_data,predictions):\n",
    "    rets = pd.DataFrame([],columns=['Long','Short'])\n",
    "    k = 10\n",
    "    for day in sorted(predictions.keys()):\n",
    "        preds = predictions[day]\n",
    "        test_returns = test_data[test_data[:,0]==day][:,-2]\n",
    "        top_preds = predictions[day].argsort()[-k:][::-1] \n",
    "        trans_long = test_returns[top_preds]\n",
    "        worst_preds = predictions[day].argsort()[:k][::-1] \n",
    "        trans_short = -test_returns[worst_preds]\n",
    "        rets.loc[day] = [np.mean(trans_long),np.mean(trans_short)] \n",
    "    print('Result : ',rets.mean())  \n",
    "    return rets       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e81934",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_label(df_open,df_close,perc=[0.5,0.5]):\n",
    "    if not np.all(df_close.iloc[:,0]==df_open.iloc[:,0]):\n",
    "        print('Date Index issue')\n",
    "        return\n",
    "    perc = [0.]+list(np.cumsum(perc))\n",
    "    label = (df_close.iloc[:,1:]/df_open.iloc[:,1:]-1).apply(\n",
    "            lambda x: pd.qcut(x.rank(method='first'),perc,labels=False), axis=1)\n",
    "    return label[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7af9afa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_stock_data(df_open,df_close,st,m=240):\n",
    "    st_data = pd.DataFrame([])\n",
    "    st_data['Date'] = list(df_close['Date'])\n",
    "    st_data['Name'] = [st]*len(st_data)\n",
    "    daily_change = df_close[st]/df_open[st]-1\n",
    "    for k in range(m)[::-1]:\n",
    "        st_data['IntraR'+str(k)] = daily_change.shift(k)\n",
    "\n",
    "    st_data['IntraR-future'] = daily_change.shift(-1)    \n",
    "    st_data['label'] = list(label[st])+[np.nan] \n",
    "    st_data['Month'] = list(df_close['Date'].str[:-3])\n",
    "    st_data = st_data.dropna()\n",
    "    \n",
    "    trade_year = st_data['Month'].str[:4]\n",
    "    st_data = st_data.drop(columns=['Month'])\n",
    "    st_train_data = st_data[trade_year<str(test_year)]\n",
    "    st_test_data = st_data[trade_year==str(test_year)]\n",
    "    return np.array(st_train_data),np.array(st_test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f9d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_normalize(train_data,test_data):\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(train_data[:,2:-2])\n",
    "    train_data[:,2:-2] = scaler.transform(train_data[:,2:-2])\n",
    "    test_data[:,2:-2] = scaler.transform(test_data[:,2:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46431f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'models-Intraday-240-1-LSTM'\n",
    "result_folder = 'results-Intraday-240-1-LSTM'\n",
    "for directory in [model_folder,result_folder]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5af32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "1993\n",
      "----------------------------------------\n",
      "(251416, 244) (121079, 244) 18.754034996032715\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m66,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,818</span> (261.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,818\u001b[0m (261.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,818</span> (261.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,818\u001b[0m (261.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m scalar_normalize(train_data,test_data)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_data\u001b[38;5;241m.\u001b[39mshape,test_data\u001b[38;5;241m.\u001b[39mshape,time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart)\n\u001b[0;32m---> 28\u001b[0m model,predictions \u001b[38;5;241m=\u001b[39m trainer(train_data,test_data)\n\u001b[1;32m     29\u001b[0m returns \u001b[38;5;241m=\u001b[39m simulate(test_data,predictions)\n\u001b[1;32m     30\u001b[0m returns\u001b[38;5;241m.\u001b[39mto_csv(result_folder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/avg_daily_rets-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(test_year)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(train_data, test_data, model_type)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     16\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m callbacks_req(model_type)\n\u001b[0;32m---> 18\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_x,\n\u001b[1;32m     19\u001b[0m           enc_y,\n\u001b[1;32m     20\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     21\u001b[0m           validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     22\u001b[0m           callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m     23\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\n\u001b[1;32m     24\u001b[0m           )\n\u001b[1;32m     26\u001b[0m dates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(test_data[:,\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     27\u001b[0m predictions \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optree/ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treespec\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;28mmap\u001b[39m(func, \u001b[38;5;241m*\u001b[39mflat_args))\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dtype: object"
     ]
    }
   ],
   "source": [
    "for test_year in range(1993,2020):\n",
    "    \n",
    "    print('-'*40)\n",
    "    print(test_year)\n",
    "    print('-'*40)\n",
    "    \n",
    "    filename = 'data/Open-'+str(test_year-3)+'.csv'\n",
    "    df_open = pd.read_csv(filename)\n",
    "    filename = 'data/Close-'+str(test_year-3)+'.csv'\n",
    "    df_close = pd.read_csv(filename)\n",
    "    \n",
    "    label = create_label(df_open,df_close)\n",
    "    stock_names = sorted(list(constituents[str(test_year-1)+'-12']))\n",
    "    train_data,test_data = [],[]\n",
    "\n",
    "    start = time.time()\n",
    "    for st in stock_names:\n",
    "        st_train_data,st_test_data = create_stock_data(df_open,df_close,st)\n",
    "        train_data.append(st_train_data)\n",
    "        test_data.append(st_test_data)\n",
    "        \n",
    "    train_data = np.concatenate([x for x in train_data])\n",
    "    test_data = np.concatenate([x for x in test_data])\n",
    "    \n",
    "    scalar_normalize(train_data,test_data)\n",
    "    print(train_data.shape,test_data.shape,time.time()-start)\n",
    "    \n",
    "    model,predictions = trainer(train_data,test_data)\n",
    "    returns = simulate(test_data,predictions)\n",
    "    returns.to_csv(result_folder+'/avg_daily_rets-'+str(test_year)+'.csv')\n",
    "    \n",
    "    result = Statistics(returns.sum(axis=1))\n",
    "    print('\\nAverage returns prior to transaction charges')\n",
    "    result.shortreport() \n",
    "    \n",
    "    with open(result_folder+\"/avg_returns.txt\", \"a\") as myfile:\n",
    "        res = '-'*30 + '\\n'\n",
    "        res += str(test_year) + '\\n'\n",
    "        res += 'Mean = ' + str(result.mean()) + '\\n'\n",
    "        res += 'Sharpe = '+str(result.sharpe()) + '\\n'\n",
    "        res += '-'*30 + '\\n'\n",
    "        myfile.write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4ff6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
