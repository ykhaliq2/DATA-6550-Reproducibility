{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Attempt to Replicate the Step-for-Step Process with Stock Price Dataset from Kaggle"
      ],
      "metadata": {
        "id": "zKvARe-nG-11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create df_close and df_open"
      ],
      "metadata": {
        "id": "7mDukm9-HOFH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tbyGd-64TsKE"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "import statsmodels.api as sm\n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "import statsmodels.api as sm\n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "from sklearn.model_selection import RepeatedKFold, cross_val_score, train_test_split\n",
        "from statsmodels.tsa.api import AutoReg, arma_order_select_ic, ARIMA, ARDL, ardl_select_order\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, cross_val_score, train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, cross_val_score, train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip historical stock prices dataset\n",
        "!unzip historical_stock_prices.csv.zip"
      ],
      "metadata": {
        "id": "2lRHLbgndUzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977cd77c-ca53-43ec-bcdc-156f3abcf2ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  historical_stock_prices.csv.zip\n",
            "replace historical_stock_prices.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "df = pd.read_csv('historical_stock_prices.csv')\n",
        "df_spx = pd.read_csv('sp500_companies.csv')"
      ],
      "metadata": {
        "id": "RxVC4VTsB3Jz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spx.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "VcXmsYQfCh1Y",
        "outputId": "67e6ac1c-d6fd-45a3-f791-29be61b668e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Exchange Symbol              Shortname               Longname  \\\n",
              "0      NMS   AAPL             Apple Inc.             Apple Inc.   \n",
              "1      NMS   NVDA     NVIDIA Corporation     NVIDIA Corporation   \n",
              "2      NMS   MSFT  Microsoft Corporation  Microsoft Corporation   \n",
              "3      NMS   AMZN       Amazon.com, Inc.       Amazon.com, Inc.   \n",
              "4      NMS  GOOGL          Alphabet Inc.          Alphabet Inc.   \n",
              "\n",
              "                   Sector                        Industry  Currentprice  \\\n",
              "0              Technology            Consumer Electronics        254.49   \n",
              "1              Technology                  Semiconductors        134.70   \n",
              "2              Technology       Software - Infrastructure        436.60   \n",
              "3       Consumer Cyclical                 Internet Retail        224.92   \n",
              "4  Communication Services  Internet Content & Information        191.41   \n",
              "\n",
              "       Marketcap        Ebitda  Revenuegrowth           City State  \\\n",
              "0  3846819807232  1.346610e+11          0.061      Cupertino    CA   \n",
              "1  3298803056640  6.118400e+10          1.224    Santa Clara    CA   \n",
              "2  3246068596736  1.365520e+11          0.160        Redmond    WA   \n",
              "3  2365033807872  1.115830e+11          0.110        Seattle    WA   \n",
              "4  2351625142272  1.234700e+11          0.151  Mountain View    CA   \n",
              "\n",
              "         Country  Fulltimeemployees  \\\n",
              "0  United States           164000.0   \n",
              "1  United States            29600.0   \n",
              "2  United States           228000.0   \n",
              "3  United States          1551000.0   \n",
              "4  United States           181269.0   \n",
              "\n",
              "                                 Longbusinesssummary    Weight  \n",
              "0  Apple Inc. designs, manufactures, and markets ...  0.069209  \n",
              "1  NVIDIA Corporation provides graphics and compu...  0.059350  \n",
              "2  Microsoft Corporation develops and supports so...  0.058401  \n",
              "3  Amazon.com, Inc. engages in the retail sale of...  0.042550  \n",
              "4  Alphabet Inc. offers various products and plat...  0.042309  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cfde8b1-21db-42a9-b7ff-ccad822ec8f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Exchange</th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Shortname</th>\n",
              "      <th>Longname</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Currentprice</th>\n",
              "      <th>Marketcap</th>\n",
              "      <th>Ebitda</th>\n",
              "      <th>Revenuegrowth</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Country</th>\n",
              "      <th>Fulltimeemployees</th>\n",
              "      <th>Longbusinesssummary</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NMS</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>Apple Inc.</td>\n",
              "      <td>Apple Inc.</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Consumer Electronics</td>\n",
              "      <td>254.49</td>\n",
              "      <td>3846819807232</td>\n",
              "      <td>1.346610e+11</td>\n",
              "      <td>0.061</td>\n",
              "      <td>Cupertino</td>\n",
              "      <td>CA</td>\n",
              "      <td>United States</td>\n",
              "      <td>164000.0</td>\n",
              "      <td>Apple Inc. designs, manufactures, and markets ...</td>\n",
              "      <td>0.069209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NMS</td>\n",
              "      <td>NVDA</td>\n",
              "      <td>NVIDIA Corporation</td>\n",
              "      <td>NVIDIA Corporation</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Semiconductors</td>\n",
              "      <td>134.70</td>\n",
              "      <td>3298803056640</td>\n",
              "      <td>6.118400e+10</td>\n",
              "      <td>1.224</td>\n",
              "      <td>Santa Clara</td>\n",
              "      <td>CA</td>\n",
              "      <td>United States</td>\n",
              "      <td>29600.0</td>\n",
              "      <td>NVIDIA Corporation provides graphics and compu...</td>\n",
              "      <td>0.059350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NMS</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>Microsoft Corporation</td>\n",
              "      <td>Microsoft Corporation</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Software - Infrastructure</td>\n",
              "      <td>436.60</td>\n",
              "      <td>3246068596736</td>\n",
              "      <td>1.365520e+11</td>\n",
              "      <td>0.160</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>United States</td>\n",
              "      <td>228000.0</td>\n",
              "      <td>Microsoft Corporation develops and supports so...</td>\n",
              "      <td>0.058401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NMS</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>Amazon.com, Inc.</td>\n",
              "      <td>Amazon.com, Inc.</td>\n",
              "      <td>Consumer Cyclical</td>\n",
              "      <td>Internet Retail</td>\n",
              "      <td>224.92</td>\n",
              "      <td>2365033807872</td>\n",
              "      <td>1.115830e+11</td>\n",
              "      <td>0.110</td>\n",
              "      <td>Seattle</td>\n",
              "      <td>WA</td>\n",
              "      <td>United States</td>\n",
              "      <td>1551000.0</td>\n",
              "      <td>Amazon.com, Inc. engages in the retail sale of...</td>\n",
              "      <td>0.042550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NMS</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>Alphabet Inc.</td>\n",
              "      <td>Alphabet Inc.</td>\n",
              "      <td>Communication Services</td>\n",
              "      <td>Internet Content &amp; Information</td>\n",
              "      <td>191.41</td>\n",
              "      <td>2351625142272</td>\n",
              "      <td>1.234700e+11</td>\n",
              "      <td>0.151</td>\n",
              "      <td>Mountain View</td>\n",
              "      <td>CA</td>\n",
              "      <td>United States</td>\n",
              "      <td>181269.0</td>\n",
              "      <td>Alphabet Inc. offers various products and plat...</td>\n",
              "      <td>0.042309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cfde8b1-21db-42a9-b7ff-ccad822ec8f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cfde8b1-21db-42a9-b7ff-ccad822ec8f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cfde8b1-21db-42a9-b7ff-ccad822ec8f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79245302-a668-4ad6-9712-3dde221dfbcd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79245302-a668-4ad6-9712-3dde221dfbcd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79245302-a668-4ad6-9712-3dde221dfbcd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_spx",
              "summary": "{\n  \"name\": \"df_spx\",\n  \"rows\": 502,\n  \"fields\": [\n    {\n      \"column\": \"Exchange\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"NYQ\",\n          \"NGM\",\n          \"NMS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Symbol\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 502,\n        \"samples\": [\n          \"DECK\",\n          \"KKR\",\n          \"ANSS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shortname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 499,\n        \"samples\": [\n          \"Bio-Techne Corp\",\n          \"Charles Schwab Corporation (The\",\n          \"Hess Corporation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Longname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 499,\n        \"samples\": [\n          \"Bio-Techne Corporation\",\n          \"The Charles Schwab Corporation\",\n          \"Hess Corporation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Healthcare\",\n          \"Technology\",\n          \"Utilities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Industry\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"Consulting Services\",\n          \"Internet Content & Information\",\n          \"Semiconductor Equipment & Materials\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Currentprice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 489.20502652018973,\n        \"min\": 9.4,\n        \"max\": 8276.78,\n        \"num_unique_values\": 499,\n        \"samples\": [\n          109.89,\n          147.58,\n          57.48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Marketcap\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 344007401496,\n        \"min\": 4664099328,\n        \"max\": 3846819807232,\n        \"num_unique_values\": 502,\n        \"samples\": [\n          32050984960,\n          136186535936,\n          29591330816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ebitda\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16242128052.501644,\n        \"min\": -3991000064.0,\n        \"max\": 149547008000.0,\n        \"num_unique_values\": 469,\n        \"samples\": [\n          9164000256.0,\n          14364000256.0,\n          16750999552.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Revenuegrowth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18024695190297257,\n        \"min\": -0.602,\n        \"max\": 1.632,\n        \"num_unique_values\": 260,\n        \"samples\": [\n          -0.056,\n          0.201,\n          0.313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 235,\n        \"samples\": [\n          \"Cleveland\",\n          \"Madison\",\n          \"North Reading\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"ID\",\n          \"MA\",\n          \"OH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Ireland\",\n          \"Canada\",\n          \"United States\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fulltimeemployees\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 139598.81229761872,\n        \"min\": 28.0,\n        \"max\": 2100000.0,\n        \"num_unique_values\": 387,\n        \"samples\": [\n          12600.0,\n          16835.0,\n          5400.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Longbusinesssummary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 499,\n        \"samples\": [\n          \"Bio-Techne Corporation, together with its subsidiaries, develops, manufactures, and sells life science reagents, instruments, and services for the research, diagnostics, and bioprocessing markets worldwide. The company operates through two segments, Protein Sciences, and Diagnostics and Genomics. The Protein Sciences segment develops and manufactures biological reagents used in various aspects of life science research, diagnostics, and cell and gene therapy, such as cytokines and growth factors, antibodies, small molecules, tissue culture sera, and cell selection technologies. This segment also offers proteomic analytical tools for automated western blot and multiplexed ELISA workflow consists of manual and automated protein analysis instruments and immunoassays for use in quantifying proteins in various biological fluids. The Diagnostics and Genomics segment develops and manufactures diagnostic products, including controls, calibrators, and diagnostic assays for regulated diagnostics market, exosome-based molecular diagnostic assays, advanced tissue-based in-situ hybridization assays for spatial genomic and tissue biopsy analysis, and genetic and oncology kits for research and clinical applications; and sells products for genetic carrier screening, oncology diagnostics, molecular controls, and research, as well as instruments and process control products for hematology, blood chemistry and gases, and coagulation controls and reagents used in various diagnostic applications. The company has strategic partnership with ALZpath, Inc. to accelerate breakthroughs in neurodegenerative disease research and treatment, including Alzheimer's disease. The company was formerly known as Techne Corporation and changed its name to Bio-Techne Corporation in November 2014. Bio-Techne Corporation was incorporated in 1976 and is headquartered in Minneapolis, Minnesota.\",\n          \"The Charles Schwab Corporation, together with its subsidiaries, operates as a savings and loan holding company that provides wealth management, securities brokerage, banking, asset management, custody, and financial advisory services in the United States and internationally. The company operates in two segments, Investor Services and Advisor Services. It offers brokerage accounts with equity and fixed income trading, margin lending, options trading, futures and forex trading, and cash management capabilities, including certificates of deposit; third-party mutual funds through the Mutual Fund Marketplace and Mutual Fund OneSource service, as well as mutual fund trading and clearing services to broker-dealers; exchange-traded funds; advisory solutions for managed portfolios, separately managed accounts, customized personal advice for tailored portfolios, specialized planning, and full-time portfolio management; banking products comprising checking and savings accounts, first lien residential real estate mortgage loans, home equity lines of credit, and pledged asset lines; and trust custody services, personal trust reporting services, and administrative trustee services. It also provides digital retirement calculators; integrated web-, mobile-, and software-based trading platforms, real-time market data, options trading, premium research, and multi-channel access; self-service education and support tools; online research and analysis tools; equity compensation plan sponsors full-service recordkeeping for stock plans, stock options, restricted stock, performance shares, and stock appreciation rights; retirement plan services; mutual fund clearing services; and advisor services, including interactive tools and educational content. The Company operates through branch offices. The Charles Schwab Corporation was founded in 1971 and is headquartered in Westlake, Texas.\",\n          \"Hess Corporation, an exploration and production company, explores, develops, produces, purchases, transports, and sells crude oil, natural gas liquids (NGLs), and natural gas. The company operates in two segments, Exploration and Production, and Midstream. It conducts production operations primarily in the United States, Guyana, the Malaysia/Thailand Joint Development Area, and Malaysia; and exploration activities principally offshore Guyana, the U.S. Gulf of Mexico, and offshore Suriname and Canada. The company is also involved in gathering, compressing, and processing natural gas; fractionating NGLs; gathering, terminaling, loading, and transporting crude oil and NGL through rail car; and storing and terminaling propane, as well as providing water handling services primarily in the Bakken Shale plays in the Williston Basin area of North Dakota. The company was incorporated in 1920 and is headquartered in New York, New York.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006189128132760053,\n        \"min\": 8.39130444266517e-05,\n        \"max\": 0.0692091524397274,\n        \"num_unique_values\": 502,\n        \"samples\": [\n          0.0005766377462676,\n          0.0024501679824236,\n          0.0005323854581097\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df only has ticker entries from Symbol in df_spx\n",
        "df = df[df['ticker'].isin(df_spx['Symbol'])]"
      ],
      "metadata": {
        "id": "ZH8dnfLeMOCx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminate all dates before 1990\n",
        "df = df[df['date'] >= '1990-01-01']"
      ],
      "metadata": {
        "id": "ZxDAwpgGhmMI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See all entries in the array\n",
        "tickers = df['ticker'].unique()\n",
        "\n",
        "# View all entries in tickers without ...\n",
        "tickers = [ticker for ticker in tickers]\n",
        "print(tickers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NGLtT1BC7bZ",
        "outputId": "9c687589-c62f-4da6-a989-9226009453bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAPL', 'RJF', 'MHK', 'SBUX', 'PFE', 'PFG', 'CLX', 'AIG', 'OMC', 'RSG', 'RF', 'MKC', 'ARE', 'EBAY', 'CME', 'RL', 'AIZ', 'AJG', 'HBAN', 'CMG', 'PGR', 'MLM', 'CMI', 'SBAC', 'ODFL', 'IPG', 'CTSH', 'ROST', 'AMAT', 'KLAC', 'GWW', 'IDXX', 'NTRS', 'MMC', 'XYL', 'CSGP', 'CMS', 'ANET', 'RMD', 'ALGN', 'MMM', 'TECH', 'LDOS', 'SO', 'IQV', 'VICI', 'NCLH', 'EXPD', 'ALB', 'PHM', 'EXPE', 'CNC', 'IRM', 'MCHP', 'ZTS', 'ALL', 'CNP', 'HSIC', 'ADSK', 'ANSS', 'NTAP', 'GNRC', 'MOH', 'TTWO', 'MOS', 'OKE', 'ATO', 'INCY', 'AMD', 'TSLA', 'AME', 'TPL', 'MPC', 'FOXA', 'CTAS', 'TPR', 'AMZN', 'DXCM', 'AMP', 'COF', 'ITW', 'AMT', 'NFLX', 'PKG', 'COO', 'AVB', 'MRK', 'PAYC', 'GLW', 'EPAM', 'ROL', 'COP', 'VZ', 'NDSN', 'COR', 'ROK', 'IVZ', 'PLD', 'JNPR', 'ROP', 'ALLE', 'CPB', 'XOM', 'GOOG', 'WM', 'PAYX', 'PYPL', 'REGN', 'ISRG', 'AVY', 'MSI', 'FRT', 'WY', 'AON', 'SWKS', 'CPT', 'AOS', 'CPRT', 'STE', 'GPC', 'APA', 'WTW', 'MTB', 'AWK', 'MTD', 'GPN', 'ZBRA', 'DLTR', 'APD', 'STT', 'TRV', 'CDNS', 'APH', 'STX', 'STZ', 'TSN', 'AXP', 'JNJ', 'BSX', 'HUBB', 'FTV', 'RCL', 'CRL', 'AZO', 'NDAQ', 'JPM', 'LULU', 'OXY', 'XEL', 'CRM', 'ULTA', 'ECL', 'JBL', 'FTNT', 'SCHW', 'ABT', 'QCOM', 'GEN', 'FSLR', 'HIG', 'SWK', 'TRGP', 'JCI', 'HII', 'PCG', 'DECK', 'ACN', 'REG', 'INTU', 'PWR', 'CSCO', 'CSX', 'ADI', 'STLD', 'ADM', 'AVGO', 'ADP', 'NWSA', 'INTC', 'HLT', 'WMB', 'BWA', 'MAA', 'PEG', 'POOL', 'TER', 'MAS', 'SYF', 'BAC', 'EFX', 'SYK', 'PEP', 'WMT', 'MAR', 'MPWR', 'AEE', 'INVH', 'SYY', 'ZBH', 'CDW', 'GIS', 'VRSK', 'TFX', 'AEP', 'VRSN', 'ADBE', 'BXP', 'BAX', 'AES', 'VRTX', 'PNC', 'MCD', 'FMC', 'SLB', 'AMGN', 'TGT', 'MCK', 'APTV', 'HAL', 'UAL', 'CFG', 'MCO', 'IBM', 'PNR', 'HAS', 'DOC', 'UPS', 'PNW', 'AFL', 'ICE', 'DAL', 'IP', 'FAST', 'HCA', 'IR', 'PPG', 'TAP', 'DOV', 'CINF', 'IT', 'MTCH', 'PPL', 'UDR', 'CAG', 'MDT', 'ERIE', 'HES', 'CBOE', 'MDLZ', 'ACGL', 'EQIX', 'CAH', 'URI', 'DPZ', 'CHD', 'IEX', 'PRU', 'IFF', 'BLK', 'KO', 'SNPS', 'JKHY', 'FOX', 'CAT', 'SNA', 'MET', 'PSA', 'USB', 'QRVO', 'BBY', 'CVS', 'NXPI', 'WRB', 'KR', 'TMUS', 'PSX', 'CVX', 'PTC', 'TXN', 'TXT', 'CBRE', 'TJX', 'DRI', 'HON', 'WST', 'LH', 'MGM', 'GDDY', 'TYL', 'A', 'TDG', 'BMY', 'LVS', 'LW', 'C', 'HPE', 'DFS', 'PANW', 'MA', 'GOOGL', 'D', 'HPQ', 'CCI', 'F', 'BIIB', 'TDY', 'UHS', 'LYB', 'EQR', 'EQT', 'LYV', 'CZR', 'MO', 'GRMN', 'K', 'PODD', 'CCL', 'SPG', 'MS', 'L', 'TMO', 'WAB', 'VST', 'MU', 'O', 'DGX', 'WAT', 'HRL', 'TEL', 'DTE', 'BA', 'ABBV', 'WBA', 'VTR', 'T', 'EIX', 'NKE', 'V', 'HST', 'BDX', 'WDC', 'DHI', 'ENPH', 'BG', 'SRE', 'HSY', 'VLO', 'ESS', 'YUM', 'FITB', 'BK', 'NI', 'NVDA', 'KEY', 'WEC', 'CHRW', 'BEN', 'HUM', 'FCX', 'DHR', 'WELL', 'PCAR', 'BR', 'VMC', 'ORCL', 'BX', 'ETN', 'KHC', 'BRO', 'LRCX', 'FDS', 'KIM', 'WFC', 'ETR', 'KEYS', 'FDX', 'CB', 'NOC', 'CE', 'CF', 'FFIV', 'AXON', 'CI', 'KKR', 'DUK', 'ON', 'KMB', 'NOW', 'CL', 'LEN', 'DVA', 'KMI', 'GILD', 'CHTR', 'CMCSA', 'SHW', 'WYNN', 'PG', 'LNT', 'KMX', 'DIS', 'PH', 'MSCI', 'NRG', 'EMN', 'EXC', 'LOW', 'FANG', 'DVN', 'NEE', 'PM', 'TSCO', 'NEM', 'EXR', 'EMR', 'JBHT', 'DE', 'BLDR', 'SMCI', 'DG', 'NSC', 'MSFT', 'MKTX', 'EA', 'EOG', 'SJM', 'ED', 'FICO', 'EL', 'ORLY', 'LKQ', 'FIS', 'COST', 'BKNG', 'ES', 'AKAM', 'NUE', 'LLY', 'TRMB', 'EW', 'LUV', 'TROW', 'FE', 'LMT', 'FI', 'DLR', 'HOLX', 'UNH', 'NVR', 'UNP', 'NWS', 'GD', 'GE', 'GM', 'GS', 'SPGI', 'HD', 'MNST']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Date count\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCnXDxKWGyXw",
        "outputId": "075cc711-2edb-4178-b544-3e160d42cfd2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2595132, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export df as a new csv\n",
        "df.to_csv('df_spx.csv', index=False)"
      ],
      "metadata": {
        "id": "fZHDW_NpISfK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make new data frame where tickers are columns, and opening prices are listed by date\n",
        "df_open = df.pivot(index='date', columns='ticker', values='open')\n",
        "df_close = df.pivot(index='date', columns='ticker', values='close')"
      ],
      "metadata": {
        "id": "9yTvtHB1M0uW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export df_open and df_close as csv files\n",
        "df_open.to_csv('df_open.csv')\n",
        "df_close.to_csv('df_close.csv')"
      ],
      "metadata": {
        "id": "v0h4RxRXNohF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change nulls to 0\n",
        "df_open = df_open.fillna(0)\n",
        "df_close = df_close.fillna(0)"
      ],
      "metadata": {
        "id": "0l049pyU6X4P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_open.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "tGjcjP0qgrHQ",
        "outputId": "0cfea3e2-4d57-414a-e03c-f4935a8f72f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ticker        A      AAPL  ABBV       ABT  ACGL  ACN      ADBE       ADI  \\\n",
              "date                                                                       \n",
              "1990-01-02  0.0  1.258929   0.0  3.829686   0.0  0.0  1.265625  1.645833   \n",
              "1990-01-03  0.0  1.357143   0.0  3.892812   0.0  0.0  1.281250  1.583333   \n",
              "1990-01-04  0.0  1.366071   0.0  3.906841   0.0  0.0  1.343750  1.500000   \n",
              "1990-01-05  0.0  1.348214   0.0  3.878784   0.0  0.0  1.375000  1.500000   \n",
              "1990-01-08  0.0  1.339286   0.0  3.815657   0.0  0.0  1.406250  1.500000   \n",
              "\n",
              "ticker           ADM       ADP  ...  WTW      WY  WYNN      XEL       XOM  \\\n",
              "date                            ...                                         \n",
              "1990-01-02  8.538174  4.820343  ...  0.0  27.375   0.0  19.8125  12.46875   \n",
              "1990-01-03  8.538174  4.944259  ...  0.0  28.375   0.0  20.1250  12.46875   \n",
              "1990-01-04  8.538174  4.919476  ...  0.0  27.500   0.0  20.0625  12.34375   \n",
              "1990-01-05  8.491771  4.857518  ...  0.0  27.125   0.0  19.5625  12.25000   \n",
              "1990-01-08  8.027740  4.832734  ...  0.0  27.125   0.0  19.3750  12.18750   \n",
              "\n",
              "ticker      XYL  YUM  ZBH  ZBRA  ZTS  \n",
              "date                                  \n",
              "1990-01-02  0.0  0.0  0.0   0.0  0.0  \n",
              "1990-01-03  0.0  0.0  0.0   0.0  0.0  \n",
              "1990-01-04  0.0  0.0  0.0   0.0  0.0  \n",
              "1990-01-05  0.0  0.0  0.0   0.0  0.0  \n",
              "1990-01-08  0.0  0.0  0.0   0.0  0.0  \n",
              "\n",
              "[5 rows x 458 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-feb4bb65-e059-4ebb-893e-6ac061f474af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>ticker</th>\n",
              "      <th>A</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>ABBV</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ACGL</th>\n",
              "      <th>ACN</th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADI</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>WY</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XOM</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1990-01-02</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.258929</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.829686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.265625</td>\n",
              "      <td>1.645833</td>\n",
              "      <td>8.538174</td>\n",
              "      <td>4.820343</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.8125</td>\n",
              "      <td>12.46875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-01-03</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.357143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.892812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.281250</td>\n",
              "      <td>1.583333</td>\n",
              "      <td>8.538174</td>\n",
              "      <td>4.944259</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.1250</td>\n",
              "      <td>12.46875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-01-04</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.366071</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.906841</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.343750</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>8.538174</td>\n",
              "      <td>4.919476</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0625</td>\n",
              "      <td>12.34375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-01-05</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.348214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.878784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>8.491771</td>\n",
              "      <td>4.857518</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.5625</td>\n",
              "      <td>12.25000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-01-08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.339286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.815657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.406250</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>8.027740</td>\n",
              "      <td>4.832734</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.3750</td>\n",
              "      <td>12.18750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  458 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-feb4bb65-e059-4ebb-893e-6ac061f474af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-feb4bb65-e059-4ebb-893e-6ac061f474af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-feb4bb65-e059-4ebb-893e-6ac061f474af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bda2dc94-8b39-4f4b-b2d8-4512b0c7e543\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bda2dc94-8b39-4f4b-b2d8-4512b0c7e543')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bda2dc94-8b39-4f4b-b2d8-4512b0c7e543 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_open"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Dataset creation with Non-Overlapping Testing Period"
      ],
      "metadata": {
        "id": "REICG6jLknRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data with a 4-year window, 1-year stride, each study period is approxiamtely 756 days, each trading period is 252 days.\n",
        "\n",
        "Initial paper showed 26 study periods, our results show 25 due to absence of days in the dataset."
      ],
      "metadata": {
        "id": "FBbz9OGEJLEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generated with ChatGPT"
      ],
      "metadata": {
        "id": "5sTh3IFOJG7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "df_open = pd.read_csv(\"df_open.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
        "df_close = pd.read_csv(\"df_close.csv\", parse_dates=[\"date\"], index_col=\"date\")  # Ensure df_close is available\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df_open.sort_index(inplace=True)\n",
        "df_close.sort_index(inplace=True)\n",
        "\n",
        "# Study period parameters\n",
        "window_size = 4 * 252  # 4 years in trading days\n",
        "stride = 1 * 252  # 1-year stride\n",
        "train_size = 3 * 252  # 3-year training\n",
        "trade_size = 1 * 252  # 1-year trading\n",
        "\n",
        "study_periods = []\n",
        "\n",
        "for start in range(0, len(df_open) - window_size + 1, stride):\n",
        "    train_start = start\n",
        "    train_end = start + train_size\n",
        "    trade_start = train_end\n",
        "    trade_end = trade_start + trade_size\n",
        "\n",
        "    train_open = df_open.iloc[train_start:train_end]\n",
        "    trade_open = df_open.iloc[trade_start:trade_end]\n",
        "    train_close = df_close.iloc[train_start:train_end]\n",
        "    trade_close = df_close.iloc[trade_start:trade_end]\n",
        "\n",
        "    study_periods.append({\n",
        "        \"train_open\": train_open,\n",
        "        \"trade_open\": trade_open,\n",
        "        \"train_close\": train_close,\n",
        "        \"trade_close\": trade_close\n",
        "    })\n",
        "\n",
        "# Example: Access the first study period\n",
        "first_period = study_periods[0]\n",
        "print(\"First study period - Training Open Prices:\\n\", first_period[\"train_open\"].head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDJbZ9M6gmY7",
        "outputId": "31fded67-52e4-4c0a-ef05-4f2892a40654"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First study period - Training Open Prices:\n",
            "              A      AAPL  ABBV       ABT  ACGL  ACN      ADBE       ADI  \\\n",
            "date                                                                      \n",
            "1990-01-02 NaN  1.258929   NaN  3.829686   NaN  NaN  1.265625  1.645833   \n",
            "1990-01-03 NaN  1.357143   NaN  3.892812   NaN  NaN  1.281250  1.583333   \n",
            "1990-01-04 NaN  1.366071   NaN  3.906841   NaN  NaN  1.343750  1.500000   \n",
            "1990-01-05 NaN  1.348214   NaN  3.878784   NaN  NaN  1.375000  1.500000   \n",
            "1990-01-08 NaN  1.339286   NaN  3.815657   NaN  NaN  1.406250  1.500000   \n",
            "\n",
            "                 ADM       ADP  ...  WTW      WY  WYNN      XEL       XOM  \\\n",
            "date                            ...                                         \n",
            "1990-01-02  8.538174  4.820343  ...  NaN  27.375   NaN  19.8125  12.46875   \n",
            "1990-01-03  8.538174  4.944259  ...  NaN  28.375   NaN  20.1250  12.46875   \n",
            "1990-01-04  8.538174  4.919476  ...  NaN  27.500   NaN  20.0625  12.34375   \n",
            "1990-01-05  8.491771  4.857518  ...  NaN  27.125   NaN  19.5625  12.25000   \n",
            "1990-01-08  8.027740  4.832734  ...  NaN  27.125   NaN  19.3750  12.18750   \n",
            "\n",
            "            XYL  YUM  ZBH  ZBRA  ZTS  \n",
            "date                                  \n",
            "1990-01-02  NaN  NaN  NaN   NaN  NaN  \n",
            "1990-01-03  NaN  NaN  NaN   NaN  NaN  \n",
            "1990-01-04  NaN  NaN  NaN   NaN  NaN  \n",
            "1990-01-05  NaN  NaN  NaN   NaN  NaN  \n",
            "1990-01-08  NaN  NaN  NaN   NaN  NaN  \n",
            "\n",
            "[5 rows x 458 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2.1: Features Selection"
      ],
      "metadata": {
        "id": "yPJoqEiIJyAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 10\n",
        "first_study = study_periods[0]\n",
        "trade_open = first_study[\"trade_open\"]\n",
        "trade_close = first_study[\"trade_close\"]\n",
        "\n",
        "# Choosing the last available day in the trading period as \n",
        "tau = trade_open.index[-1]\n",
        "\n",
        "# Extracting opening prices for  and adjusted closing prices for -1\n",
        "op_tau = trade_open.loc[tau]\n",
        "cp_tau_minus_1 = trade_close.loc[trade_open.index[-2]]  # Previous day's closing\n",
        "\n",
        "# Compute intraday return ir,0 = (cp / op) - 1\n",
        "intraday_returns = (cp_tau_minus_1 / op_tau) - 1\n",
        "\n",
        "# Select top k highest and lowest intraday return stocks\n",
        "top_k_stocks = intraday_returns.nlargest(k)\n",
        "bottom_k_stocks = intraday_returns.nsmallest(k)\n",
        "\n",
        "# Output the results\n",
        "print(\"Top k stocks with highest intraday returns:\")\n",
        "print(top_k_stocks)\n",
        "\n",
        "print(\"\\nBottom k stocks with lowest intraday returns:\")\n",
        "print(bottom_k_stocks)\n"
      ],
      "metadata": {
        "id": "B3UtiTnyJ41d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e76fd0f-6bfb-49ab-c94c-a67ff61b8391"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top k stocks with highest intraday returns:\n",
            "ROP     0.067797\n",
            "VRTX    0.045455\n",
            "BAX     0.032967\n",
            "TRMB    0.028571\n",
            "AAPL    0.027523\n",
            "GILD    0.022222\n",
            "BIIB    0.022222\n",
            "NDSN    0.019802\n",
            "UDR     0.019802\n",
            "SYK     0.018182\n",
            "dtype: float64\n",
            "\n",
            "Bottom k stocks with lowest intraday returns:\n",
            "JBL    -0.032258\n",
            "CSCO   -0.031873\n",
            "INCY   -0.027778\n",
            "KIM    -0.025830\n",
            "TYL    -0.025641\n",
            "TROW   -0.017241\n",
            "EXPD   -0.016667\n",
            "JKHY   -0.016667\n",
            "PFE    -0.016605\n",
            "CTAS   -0.015625\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2.2: Features Generation"
      ],
      "metadata": {
        "id": "nxjcIIdJhkZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Load data\n",
        "df_open = pd.read_csv(\"df_open.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
        "df_close = pd.read_csv(\"df_close.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df_open.sort_index(inplace=True)\n",
        "df_close.sort_index(inplace=True)\n",
        "\n",
        "# Debug: Check if column names are correct\n",
        "print(f\"df_open columns: {df_open.columns}\")\n",
        "print(f\"df_close columns: {df_close.columns}\")\n",
        "\n",
        "# Compute features for each stock\n",
        "intraday_return = (df_close / df_open) - 1  # ir(s)_t,1\n",
        "close_to_close_return = df_close.pct_change()  # cr(s)_t,1\n",
        "open_to_open_return = df_open.pct_change()  # or(s)_t,1\n",
        "\n",
        "# Debug: Check shape before merging\n",
        "print(f\"Intraday return shape: {intraday_return.shape}\")\n",
        "print(f\"Close-to-close return shape: {close_to_close_return.shape}\")\n",
        "print(f\"Open-to-open return shape: {open_to_open_return.shape}\")\n",
        "\n",
        "# Merge features into a single DataFrame\n",
        "df_features = pd.concat(\n",
        "    [intraday_return, close_to_close_return, open_to_open_return],\n",
        "    axis=1,\n",
        "    keys=['ir', 'cr', 'or']\n",
        ")\n",
        "\n",
        "# Debug: Check structure after merging\n",
        "print(f\"df_features columns:\\n{df_features.columns}\")\n",
        "\n",
        "# Ensure df_features has MultiIndex format\n",
        "if not isinstance(df_features.columns, pd.MultiIndex):\n",
        "    print(\"Fixing df_features column format...\")\n",
        "    df_features.columns = pd.MultiIndex.from_tuples(df_features.columns)\n",
        "\n",
        "# Remove NaNs caused by pct_change()\n",
        "df_features.dropna(inplace=True)\n",
        "\n",
        "# Debug: Show sample data\n",
        "print(\"Sample df_features after merging and cleaning:\")\n",
        "print(df_features.head())\n",
        "\n",
        "# Apply Robust Scaler standardization\n",
        "def robust_scale(series):\n",
        "    Q1, Q2, Q3 = series.quantile([0.25, 0.5, 0.75])\n",
        "    return (series - Q2) / (Q3 - Q1) if (Q3 - Q1) != 0 else series  # Avoid division by zero\n",
        "\n",
        "df_scaled = df_features.groupby(axis=1, level=1).apply(lambda x: x.apply(robust_scale))\n",
        "\n",
        "# Debug: Ensure we still have data\n",
        "if df_scaled.empty:\n",
        "    print(\"Error: No data available after feature scaling.\")\n",
        "    exit()\n",
        "\n",
        "# Debug: Show scaled data\n",
        "print(\"Sample df_scaled:\")\n",
        "print(df_scaled.head())\n",
        "\n",
        "# Generate overlapping sequences of 240 time steps for training\n",
        "sequence_length = 240\n",
        "X, y = [], []\n",
        "\n",
        "# Get all stock tickers\n",
        "# Get actual stock tickers\n",
        "stock_tickers = df_scaled.columns.get_level_values(1).unique().tolist()\n",
        "print(f\"Stock tickers found: {stock_tickers}\")\n",
        "\n",
        "X, y = [], []\n",
        "sequence_length = 240\n",
        "\n",
        "for stock in stock_tickers:\n",
        "    stock_data = df_scaled.loc[:, (slice(None), stock)].values  # Extracts (ir, cr, or) features\n",
        "    print(f\"Processing stock: {stock}\")\n",
        "    print(f\"Stock data shape: {stock_data.shape}\")\n",
        "\n",
        "    if stock_data.shape[0] <= sequence_length:\n",
        "        print(f\"Skipping stock {stock} due to insufficient data ({stock_data.shape[0]} rows).\")\n",
        "        continue  # Skip if not enough data\n",
        "\n",
        "    # Generate training sequences\n",
        "    for t in range(sequence_length, len(stock_data) - 1):  # Ensure 241st return exists\n",
        "        X.append(stock_data[t-sequence_length:t])  # Last 240 timesteps\n",
        "        y.append(1 if intraday_return.iloc[t+1][stock] > 0 else -1)  # Predict direction\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"Input shape: {X.shape} (samples, time steps, features)\")\n",
        "print(f\"Target shape: {y.shape} (samples,)\")\n",
        "\n",
        "if X.shape[0] == 0:\n",
        "    print(\"Error: No training samples were generated. Ensure your dataset has enough rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXzmTQ3EhkFa",
        "outputId": "177095d1-47b0-4875-ace2-c7ed899cd5d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_open columns: Index(['A', 'AAPL', 'ABBV', 'ABT', 'ACGL', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP',\n",
            "       ...\n",
            "       'WTW', 'WY', 'WYNN', 'XEL', 'XOM', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZTS'],\n",
            "      dtype='object', length=458)\n",
            "df_close columns: Index(['A', 'AAPL', 'ABBV', 'ABT', 'ACGL', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP',\n",
            "       ...\n",
            "       'WTW', 'WY', 'WYNN', 'XEL', 'XOM', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZTS'],\n",
            "      dtype='object', length=458)\n",
            "Intraday return shape: (7220, 458)\n",
            "Close-to-close return shape: (7220, 458)\n",
            "Open-to-open return shape: (7220, 458)\n",
            "df_features columns:\n",
            "MultiIndex([('ir',    'A'),\n",
            "            ('ir', 'AAPL'),\n",
            "            ('ir', 'ABBV'),\n",
            "            ('ir',  'ABT'),\n",
            "            ('ir', 'ACGL'),\n",
            "            ('ir',  'ACN'),\n",
            "            ('ir', 'ADBE'),\n",
            "            ('ir',  'ADI'),\n",
            "            ('ir',  'ADM'),\n",
            "            ('ir',  'ADP'),\n",
            "            ...\n",
            "            ('or',  'WTW'),\n",
            "            ('or',   'WY'),\n",
            "            ('or', 'WYNN'),\n",
            "            ('or',  'XEL'),\n",
            "            ('or',  'XOM'),\n",
            "            ('or',  'XYL'),\n",
            "            ('or',  'YUM'),\n",
            "            ('or',  'ZBH'),\n",
            "            ('or', 'ZBRA'),\n",
            "            ('or',  'ZTS')],\n",
            "           length=1374)\n",
            "Sample df_features after merging and cleaning:\n",
            "                  ir                                                    \\\n",
            "                   A      AAPL      ABBV       ABT      ACGL       ACN   \n",
            "date                                                                     \n",
            "2018-01-17  0.004741  0.016747  0.013204  0.003914 -0.009363  0.006977   \n",
            "2018-01-18 -0.000138 -0.000613 -0.004603  0.004934 -0.014251  0.005058   \n",
            "2018-01-19  0.008140 -0.000840  0.002971  0.001351  0.012665  0.000928   \n",
            "2018-01-22  0.004237 -0.001692  0.017096  0.011719  0.014992  0.001365   \n",
            "2018-01-23 -0.008238 -0.001466 -0.007441 -0.004872  0.009404 -0.002542   \n",
            "\n",
            "                                                    ...        or            \\\n",
            "                ADBE       ADI       ADM       ADP  ...       WTW        WY   \n",
            "date                                                ...                       \n",
            "2018-01-17  0.012731  0.016702  0.000000  0.017083  ... -0.011167 -0.013296   \n",
            "2018-01-18 -0.000051  0.017368 -0.009785 -0.005593  ...  0.044160  0.008027   \n",
            "2018-01-19 -0.002599 -0.015363  0.011108  0.002063  ... -0.007748  0.004551   \n",
            "2018-01-22  0.010935  0.002697  0.038125  0.009207  ...  0.028957  0.015006   \n",
            "2018-01-23 -0.010875 -0.002275  0.006139  0.002134  ...  0.027668  0.003905   \n",
            "\n",
            "                                                                        \\\n",
            "                WYNN       XEL       XOM       XYL       YUM       ZBH   \n",
            "date                                                                     \n",
            "2018-01-17  0.005627  0.009311 -0.006155  0.001693 -0.008921 -0.000654   \n",
            "2018-01-18  0.010492  0.001098  0.006537 -0.002254 -0.001680  0.001473   \n",
            "2018-01-19  0.019555 -0.008337 -0.002279  0.009881  0.003006 -0.001470   \n",
            "2018-01-22  0.061330  0.006637 -0.004568  0.005731  0.004555  0.010308   \n",
            "2018-01-23  0.049843 -0.003956  0.012390  0.007644  0.010858  0.017409   \n",
            "\n",
            "                                \n",
            "                ZBRA       ZTS  \n",
            "date                            \n",
            "2018-01-17  0.003004 -0.003287  \n",
            "2018-01-18  0.005505  0.011080  \n",
            "2018-01-19 -0.004750  0.000522  \n",
            "2018-01-22 -0.002831 -0.000261  \n",
            "2018-01-23  0.008275  0.008217  \n",
            "\n",
            "[5 rows x 1374 columns]\n",
            "Sample df_scaled:\n",
            "                   A                          AAPL                      \\\n",
            "                  ir        cr        or        ir        cr        or   \n",
            "                   A         A         A      AAPL      AAPL      AAPL   \n",
            "date                                                                     \n",
            "2018-01-17  0.251495  0.644527 -0.262927  1.281708  1.119688 -0.597378   \n",
            "2018-01-18 -0.080632  0.070060  0.385516 -0.053661  0.013250  0.970113   \n",
            "2018-01-19  0.482908  0.675892  0.217439 -0.071085 -0.366070 -0.285185   \n",
            "2018-01-22  0.217198  0.292130  0.554354 -0.136643 -0.629412 -0.457861   \n",
            "2018-01-23 -0.631966 -0.066933  0.704075 -0.119292 -0.034012 -0.048975   \n",
            "\n",
            "                ABBV                           ABT  ...       YUM       ZBH  \\\n",
            "                  ir        cr        or        ir  ...        or        ir   \n",
            "                ABBV      ABBV      ABBV       ABT  ...       YUM       ZBH   \n",
            "date                                                ...                       \n",
            "2018-01-17  0.619256  0.809326  1.153183  0.111389  ... -0.729599  0.095459   \n",
            "2018-01-18 -0.236136 -0.309563  0.506242  0.184223  ... -0.124777 -0.173167   \n",
            "2018-01-19  0.127701  0.321616 -0.024290 -0.071776  ...  0.266621  0.649896   \n",
            "2018-01-22  0.806249  0.782393  0.113921  0.669008  ...  0.396020  1.452116   \n",
            "2018-01-23 -0.372484 -0.554756  0.572482 -0.516405  ...  0.922523 -0.665663   \n",
            "\n",
            "                                    ZBRA                           ZTS  \\\n",
            "                  cr        or        ir        cr        or        ir   \n",
            "                 ZBH       ZBH      ZBRA      ZBRA      ZBRA       ZTS   \n",
            "date                                                                     \n",
            "2018-01-17  0.354533 -0.019393  0.093024  0.173120  0.036239  0.810809   \n",
            "2018-01-18 -0.161809  0.113032 -0.411109 -0.203542  0.153036 -0.370191   \n",
            "2018-01-19  0.575709 -0.070227  0.043585  0.221037 -0.325944 -0.141394   \n",
            "2018-01-22  1.226130  0.663210  0.410891  0.228091 -0.236325  0.663630   \n",
            "2018-01-23 -0.782278  1.105423  0.558819  0.562335  0.282409  0.185754   \n",
            "\n",
            "                                \n",
            "                  cr        or  \n",
            "                 ZTS       ZTS  \n",
            "date                            \n",
            "2018-01-17  0.882837 -0.225164  \n",
            "2018-01-18 -0.419432  0.594103  \n",
            "2018-01-19  0.144366 -0.007978  \n",
            "2018-01-22  0.583597 -0.052610  \n",
            "2018-01-23  0.003593  0.430829  \n",
            "\n",
            "[5 rows x 1374 columns]\n",
            "Stock tickers found: ['ir', 'cr', 'or']\n",
            "Processing stock: ir\n",
            "Stock data shape: (138, 458)\n",
            "Skipping stock ir due to insufficient data (138 rows).\n",
            "Processing stock: cr\n",
            "Stock data shape: (138, 458)\n",
            "Skipping stock cr due to insufficient data (138 rows).\n",
            "Processing stock: or\n",
            "Stock data shape: (138, 458)\n",
            "Skipping stock or due to insufficient data (138 rows).\n",
            "Input shape: (0,) (samples, time steps, features)\n",
            "Target shape: (0,) (samples,)\n",
            "Error: No training samples were generated. Ensure your dataset has enough rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We run into a roadblock.  The input shape and target shape should ideally be 241 features to train and test split, but our dataset consists of missing days and lots of null values which could interrupt time series modeling lookbacks.  "
      ],
      "metadata": {
        "id": "wvndmXuHHTpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verify datasets are able to work with given code"
      ],
      "metadata": {
        "id": "KNtxNkZAATGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generated with ChatGPT"
      ],
      "metadata": {
        "id": "9z252MfDAW00"
      }
    },
    {
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# -------------------- Setup --------------------\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SEED = 9\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Load data\n",
        "SP500_df = pd.read_csv('SPXconst.csv')\n",
        "df_open = pd.read_csv('Open-1990.csv')\n",
        "df_close = pd.read_csv('Close-1990.csv')\n",
        "\n",
        "# Clean and parse SP500 constituents\n",
        "constituents = {\n",
        "    '-'.join(col.split('/')[::-1]): set(SP500_df[col].dropna())\n",
        "    for col in SP500_df.columns\n",
        "}\n",
        "test_year = 1991\n",
        "start_year = max(1990, test_year - 3)\n",
        "months = [\n",
        "    f\"{t}-0{m}\" if m < 10 else f\"{t}-{m}\"\n",
        "    for t in range(start_year, test_year) for m in range(1, 13)\n",
        "]\n",
        "valid_months = [m for m in months if m in constituents]\n",
        "constituents_train = {\n",
        "    test_year: set(i for sublist in [list(constituents[m]) for m in valid_months] for i in sublist)\n",
        "}\n",
        "\n",
        "# Create necessary folders\n",
        "model_folder = 'models-Intraday-240-3-LSTM'\n",
        "result_folder = 'results-Intraday-240-3-LSTM'\n",
        "for directory in [model_folder, result_folder]:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# Dummy statistics class\n",
        "class DummyStatistics:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def mean(self):\n",
        "        return self.data.mean()\n",
        "\n",
        "    def sharpe(self):\n",
        "        return self.data.mean() / self.data.std() * np.sqrt(252)\n",
        "\n",
        "    def shortreport(self):\n",
        "        print(\"Mean:\", self.mean())\n",
        "        print(\"Sharpe Ratio:\", self.sharpe())\n",
        "\n",
        "# -------------------- Model and Helper Functions --------------------\n",
        "def makeLSTM():\n",
        "    inputs = Input(shape=(240, 3))\n",
        "    x = LSTM(25, return_sequences=False)(inputs)\n",
        "    x = Dropout(0.1)(x)\n",
        "    outputs = Dense(2, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def callbacks_req(model_type='LSTM'):\n",
        "    csv_logger = CSVLogger(f\"{model_folder}/training-log-{model_type}-{test_year}.csv\")\n",
        "    filepath = f\"{model_folder}/model-{model_type}-{test_year}-E{{epoch:02d}}.h5\"\n",
        "    model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=False)\n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)\n",
        "    return [csv_logger, earlyStopping, model_checkpoint]\n",
        "\n",
        "def reshaper(arr):\n",
        "    arr = np.array(np.split(arr, 3, axis=1))\n",
        "    arr = np.swapaxes(arr, 0, 1)\n",
        "    arr = np.swapaxes(arr, 1, 2)\n",
        "    return arr\n",
        "\n",
        "def create_label(df_open, df_close, perc=[0.5, 0.5]):\n",
        "    if not np.all(df_close.iloc[:, 0] == df_open.iloc[:, 0]):\n",
        "        raise ValueError(\"Date Index mismatch between Open and Close data\")\n",
        "    perc = [0.] + list(np.cumsum(perc))\n",
        "    label = (df_close.iloc[:, 1:] / df_open.iloc[:, 1:] - 1).apply(\n",
        "        lambda x: pd.qcut(x.rank(method='first'), perc, labels=False), axis=1)\n",
        "    return label[1:]\n",
        "\n",
        "def create_stock_data(df_open, df_close, st, label, m=240):\n",
        "    st_data = pd.DataFrame()\n",
        "    st_data['Date'] = df_close['Date']\n",
        "    st_data['Name'] = [st] * len(st_data)\n",
        "    daily_change = df_close[st] / df_open[st] - 1\n",
        "    for k in range(m)[::-1]:\n",
        "        st_data[f'IntraR{k}'] = daily_change.shift(k)\n",
        "\n",
        "    nextday_ret = (np.array(df_open[st][1:]) / np.array(df_close[st][:-1]) - 1)\n",
        "    nextday_ret = pd.Series(list(nextday_ret) + [np.nan])\n",
        "    for k in range(m)[::-1]:\n",
        "        st_data[f'NextR{k}'] = nextday_ret.shift(k)\n",
        "\n",
        "    close_change = df_close[st].pct_change()\n",
        "    for k in range(m)[::-1]:\n",
        "        st_data[f'CloseR{k}'] = close_change.shift(k)\n",
        "\n",
        "    st_data['IntraR-future'] = daily_change.shift(-1)\n",
        "    st_data['label'] = list(label[st]) + [np.nan]\n",
        "    st_data['Month'] = df_close['Date'].str[:7]\n",
        "    st_data = st_data.dropna()\n",
        "\n",
        "    trade_year = st_data['Month'].str[:4]\n",
        "    st_data = st_data.drop(columns=['Month'])\n",
        "    st_train_data = st_data[trade_year < str(test_year)]\n",
        "    st_test_data = st_data[trade_year == str(test_year)]\n",
        "    return np.array(st_train_data), np.array(st_test_data)\n",
        "\n",
        "def scalar_normalize(train_data, test_data):\n",
        "    scaler = RobustScaler()\n",
        "    scaler.fit(train_data[:, 2:-2])\n",
        "    train_data[:, 2:-2] = scaler.transform(train_data[:, 2:-2])\n",
        "    test_data[:, 2:-2] = scaler.transform(test_data[:, 2:-2])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def trainer(train_data, test_data):\n",
        "    np.random.shuffle(train_data)\n",
        "    train_x, train_y, train_ret = train_data[:, 2:-2], train_data[:, -1], train_data[:, -2]\n",
        "\n",
        "    # Convert train_x to numeric if it contains object dtype\n",
        "    train_x = train_x.astype(np.float32)  # or np.float64 if necessary\n",
        "\n",
        "    train_x = reshaper(train_x)\n",
        "    train_y = np.reshape(train_y, (-1, 1))\n",
        "    enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc.fit(train_y)\n",
        "    enc_y = enc.transform(train_y).toarray()\n",
        "\n",
        "    model = makeLSTM()\n",
        "    callbacks = callbacks_req()\n",
        "\n",
        "    # Train the model and capture history\n",
        "    history = model.fit(\n",
        "        train_x,\n",
        "        enc_y,\n",
        "        epochs=1000,\n",
        "        validation_split=0.2,\n",
        "        callbacks=callbacks,\n",
        "        batch_size=512,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Predict on test data\n",
        "    dates = list(set(test_data[:, 0]))\n",
        "    predictions = {}\n",
        "    for day in dates:\n",
        "        test_d = test_data[test_data[:, 0] == day]\n",
        "        # Ensure test_d is numeric before reshaping and prediction\n",
        "        test_d = test_d[:, 2:-2].astype(np.float32)  # or np.float64 if necessary\n",
        "        test_d = reshaper(test_d)\n",
        "        predictions[day] = model.predict(test_d)[:, 1]\n",
        "    return model, predictions\n",
        "def simulate(test_data, predictions):\n",
        "    rets = pd.DataFrame([], columns=['Long', 'Short'])\n",
        "    k = 10\n",
        "    for day in sorted(predictions.keys()):\n",
        "        preds = predictions[day]\n",
        "        test_returns = test_data[test_data[:, 0] == day][:, -2]\n",
        "        top_preds = preds.argsort()[-k:][::-1]\n",
        "        worst_preds = preds.argsort()[:k][::-1]\n",
        "        rets.loc[day] = [\n",
        "            np.mean(test_returns[top_preds]),\n",
        "            -np.mean(test_returns[worst_preds])\n",
        "        ]\n",
        "    print('Result:', rets.mean())\n",
        "    return rets\n",
        "\n",
        "# -------------------- Run the Process --------------------\n",
        "label = create_label(df_open, df_close)\n",
        "stock_names = sorted(list(constituents[str(test_year - 1) + '-12']))\n",
        "train_data, test_data = [], []\n",
        "\n",
        "for st in stock_names:\n",
        "    try:\n",
        "        st_train_data, st_test_data = create_stock_data(df_open, df_close, st, label)\n",
        "        train_data.append(st_train_data)\n",
        "        test_data.append(st_test_data)\n",
        "    except Exception:\n",
        "        continue  # Skip any stock with missing data\n",
        "\n",
        "train_data = np.concatenate(train_data)\n",
        "test_data = np.concatenate(test_data)\n",
        "\n",
        "scalar_normalize(train_data, test_data)\n",
        "model, predictions = trainer(train_data, test_data)\n",
        "returns = simulate(test_data, predictions)\n",
        "returns.to_csv(f\"{result_folder}/avg_daily_rets-{test_year}.csv\")\n",
        "\n",
        "# Save and print result summary\n",
        "result = DummyStatistics(returns.sum(axis=1))\n",
        "print('\\nAverage returns prior to transaction charges')\n",
        "result.shortreport()\n",
        "\n",
        "with open(f\"{result_folder}/avg_returns.txt\", \"a\") as myfile:\n",
        "    res = '-' * 30 + '\\n'\n",
        "    res += f\"{test_year}\\n\"\n",
        "    res += f\"Mean = {result.mean()}\\n\"\n",
        "    res += f\"Sharpe = {result.sharpe()}\\n\"\n",
        "    res += '-' * 30 + '\\n'\n",
        "    myfile.write(res)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr-a12tYEb1I",
        "outputId": "819a2b43-6cbb-4e99-c105-81246787e72f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Result: Long     0.009494\n",
            "Short    0.003504\n",
            "dtype: float64\n",
            "\n",
            "Average returns prior to transaction charges\n",
            "Mean: 0.012998109818857264\n",
            "Sharpe Ratio: 9.707644859424164\n"
          ]
        }
      ]
    }
  ]
}