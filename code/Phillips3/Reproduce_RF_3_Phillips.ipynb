{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913f4b1c-4748-4db0-933f-56fd4f274def",
   "metadata": {},
   "source": [
    "<h2>Things done to reproduce code</h2>\n",
    "\n",
    "1. Literature Review & Objective Definition\n",
    "\n",
    "    - Understood the original study’s goals: to compare model performance on intraday return prediction.\n",
    "      \n",
    "    - Focused on reproducing the Random Forest component using public tools and data.\n",
    "\n",
    "2. Code Migration and Environment Setup\n",
    "\n",
    "    - Adapted original codebase (which relied on proprietary Bloomberg data and an SPX constituents file) to use public data from Yahoo Finance (yfinance).\n",
    "\n",
    "    - Implemented Random Forest pipeline for training and prediction.\n",
    "\n",
    "3. Data Acquisition and Preparation\n",
    "\n",
    "    - Attempted to replace SPXconst.csv with approximated static ticker lists.\n",
    "\n",
    "    - Used yfinance to download historical Open and Adjusted Close prices.\n",
    "\n",
    "    - Created training and test datasets using rolling 3-year windows.\n",
    "\n",
    "4. Model Execution and Evaluation\n",
    "\n",
    "    - Trained Random Forest models for each year (2015–2019).\n",
    "\n",
    "    - Simulated a simple long-short trading strategy to evaluate predictions.\n",
    "\n",
    "    - Measured output: daily return averages.\n",
    "\n",
    "5. Code Adjustments for Compatibility\n",
    "\n",
    "    - Rewrote deprecated or missing functions.\n",
    "\n",
    "    - Replaced unavailable Statistics class with placeholder metrics.\n",
    "\n",
    "    - Handled missing and incomplete ticker data.\n",
    "\n",
    "    - Improved error handling and modularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df995e-f978-4396-bc66-7d579ce61c54",
   "metadata": {},
   "source": [
    "<h5>ChatGPT helped me with attempting to recreate code and get results</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499330a0-da19-48fc-8fbd-f56e4a028a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import yfinance as yf\n",
    "import os\n",
    "\n",
    "SEED = 9\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55e7d31-ff76-4cbf-a844-8f59409f2e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_tickers():\n",
    "    return ['AAPL', 'MSFT', 'JPM', 'UNH', 'XOM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb726ce-a0f5-449e-bf68-11901cd9bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = get_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6cf6cdb-c0ae-499b-8513-61c443713ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/p6lwj8pj7vgcbcr0ylpxl6940000gn/T/ipykernel_17169/1459959745.py:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(start='1990-01-01', end='2019-12-31', freq='M')\n"
     ]
    }
   ],
   "source": [
    "constituents = {}\n",
    "dates = pd.date_range(start='1990-01-01', end='2019-12-31', freq='M')\n",
    "for date in dates:\n",
    "    constituents[date.strftime('%Y-%m')] = set(all_companies)\n",
    "\n",
    "constituents_train = {}\n",
    "for test_year in range(1993, 2016):\n",
    "    months = [f\"{t}-{m:02d}\" for t in range(test_year-3, test_year) for m in range(1, 13)]\n",
    "    all_stocks = [list(constituents[m]) for m in months if m in constituents]\n",
    "    constituents_train[test_year] = set([i for sublist in all_stocks for i in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7703434-2058-4ca6-8810-693f404a75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_data, test_data):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    train_x, train_y = train_data[:, 2:-2], train_data[:, -1].astype(int)\n",
    "    print('Started training')\n",
    "    clf = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=SEED, n_jobs=-1)\n",
    "    clf.fit(train_x, train_y)\n",
    "    print('Completed', clf.score(train_x, train_y))\n",
    "\n",
    "    dates = list(set(test_data[:, 0]))\n",
    "    predictions = {}\n",
    "    for day in dates:\n",
    "        test_d = test_data[test_data[:, 0] == day][:, 2:-2]\n",
    "        predictions[day] = clf.predict_proba(test_d)[:, 1]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a1fc4d-7f86-49cb-933f-ec37bc0a3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(test_data, predictions):\n",
    "    rets = pd.DataFrame([], columns=['Long', 'Short'])\n",
    "    k = 10\n",
    "    for day in sorted(predictions.keys()):\n",
    "        preds = predictions[day]\n",
    "        test_returns = test_data[test_data[:, 0] == day][:, -2]\n",
    "        top_preds = predictions[day].argsort()[-k:][::-1]\n",
    "        trans_long = test_returns[top_preds]\n",
    "        worst_preds = predictions[day].argsort()[:k][::-1]\n",
    "        trans_short = -test_returns[worst_preds]\n",
    "        rets.loc[day] = [np.mean(trans_long), np.mean(trans_short)]\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b38fc19-a6dc-4393-ad6f-b3fa03fadb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(df_open, df_close, perc=[0.5, 0.5]):\n",
    "    if not np.all(df_close['Date'] == df_open['Date']):\n",
    "        print('Date Index issue')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if df_open.shape[1] <= 2 or df_close.shape[1] <= 2:\n",
    "        print(\"Too few tickers with valid data for label creation.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    perc = [0.] + list(np.cumsum(perc))\n",
    "    try:\n",
    "        label = (df_close.iloc[:, 1:] / df_open.iloc[:, 1:] - 1).apply(\n",
    "            lambda x: pd.qcut(x.rank(method='first'), perc, labels=False, duplicates='drop'), axis=1)\n",
    "    except Exception as e:\n",
    "        print(\"Label creation failed:\", e)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8481c1f1-f899-422d-ae5c-b488b0cd9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stock_data(df_close, df_open, st, label, test_year):\n",
    "    st_data = pd.DataFrame()\n",
    "    st_data['Date'] = df_close['Date']\n",
    "    st_data['Name'] = st\n",
    "    daily_change = df_close[st] / df_open[st] - 1\n",
    "\n",
    "    m = list(range(1, 20)) + list(range(20, 241, 20))\n",
    "    for k in m:\n",
    "        st_data[f'IntraR{k}'] = daily_change.shift(k)\n",
    "        st_data[f'CloseR{k}'] = df_close[st].pct_change(k).shift(1)\n",
    "        st_data[f'OverNR{k}'] = df_open[st] / df_close[st].shift(k) - 1\n",
    "\n",
    "    st_data['R-future'] = daily_change\n",
    "    st_data['label'] = label[st]\n",
    "    st_data['Month'] = df_close['Date'].str[:7]\n",
    "    st_data.dropna(inplace=True)\n",
    "\n",
    "    trade_year = st_data['Month'].str[:4]\n",
    "    st_data.drop(columns=['Month'], inplace=True)\n",
    "    st_train_data = st_data[trade_year < str(test_year)]\n",
    "    st_test_data = st_data[trade_year == str(test_year)]\n",
    "    return np.array(st_train_data), np.array(st_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fcd87a0-ab2d-4a02-ae7a-eac279d06a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(tickers, start, end):\n",
    "    df_open = pd.DataFrame()\n",
    "    df_close = pd.DataFrame()\n",
    "    df_open['Date'] = pd.date_range(start=start, end=end, freq='B')\n",
    "    df_close['Date'] = df_open['Date']\n",
    "    valid_tickers = []\n",
    "    print(\"Attempting to download:\", tickers)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, end=end, auto_adjust=False, progress=False)\n",
    "            if df.empty or df['Open'].isnull().all() or df['Adj Close'].isnull().all():\n",
    "                continue\n",
    "            df = df.reset_index()\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df_open[ticker] = df.set_index('Date').reindex(df_open['Date'])['Open'].values\n",
    "            df_close[ticker] = df.set_index('Date').reindex(df_close['Date'])['Adj Close'].values\n",
    "            valid_tickers.append(ticker)\n",
    "        except Exception as e:\n",
    "            print(f\"{ticker} failed: {e}\")\n",
    "            continue\n",
    "\n",
    "    df_open['Date'] = df_open['Date'].dt.strftime('%Y-%m-%d')\n",
    "    df_close['Date'] = df_close['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    print(\"Valid tickers with data:\", valid_tickers)\n",
    "    print(\"Dropped:\", set(tickers) - set(valid_tickers))\n",
    "    return df_open, df_close, valid_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b466b30d-3b80-41c3-b228-7edb6b261cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "2018\n",
      "----------------------------------------\n",
      "Attempting to download: ['AAPL', 'JPM', 'MSFT', 'UNH', 'XOM']\n",
      "AAPL failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "JPM failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "MSFT failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "UNH failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "XOM failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Valid tickers with data: []\n",
      "Dropped: {'AAPL', 'UNH', 'JPM', 'XOM', 'MSFT'}\n",
      "Skipping 2018 — only 0 tickers with data.\n",
      "----------------------------------------\n",
      "2019\n",
      "----------------------------------------\n",
      "Attempting to download: ['AAPL', 'JPM', 'MSFT', 'UNH', 'XOM']\n",
      "AAPL failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "JPM failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "MSFT failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "UNH failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "XOM failed: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Valid tickers with data: []\n",
      "Dropped: {'AAPL', 'UNH', 'JPM', 'XOM', 'MSFT'}\n",
      "Skipping 2019 — only 0 tickers with data.\n"
     ]
    }
   ],
   "source": [
    "result_folder = 'results-Intraday-240-3-RF'\n",
    "os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "for test_year in range(2018, 2020):\n",
    "    print('-'*40)\n",
    "    print(test_year)\n",
    "    print('-'*40)\n",
    "\n",
    "    tickers = sorted(list(constituents[f'{test_year-1}-12']))[:10]\n",
    "    df_open, df_close, valid_tickers = download_data(tickers, f'{test_year-3}-01-01', f'{test_year}-01-01')\n",
    "\n",
    "    if len(valid_tickers) < 3:\n",
    "        print(f\"Skipping {test_year} — only {len(valid_tickers)} tickers with data.\")\n",
    "        continue\n",
    "\n",
    "    df_open.insert(0, 'Date', df_open.pop('Date'))\n",
    "    df_close.insert(0, 'Date', df_close.pop('Date'))\n",
    "\n",
    "    label = create_label(df_open, df_close)\n",
    "    if label.empty:\n",
    "        print(f\"Skipping {test_year} due to label creation issue.\")\n",
    "        continue\n",
    "\n",
    "    train_data, test_data = [], []\n",
    "    start = time.time()\n",
    "    for st in valid_tickers:\n",
    "        try:\n",
    "            st_train, st_test = create_stock_data(df_close, df_open, st, label, test_year)\n",
    "            train_data.append(st_train)\n",
    "            test_data.append(st_test)\n",
    "        except Exception as e:\n",
    "            print(f\"{st} failed: {e}\")\n",
    "\n",
    "    if not train_data or not test_data:\n",
    "        print(f\"Skipping {test_year} — no usable training/testing data.\")\n",
    "        continue\n",
    "\n",
    "    train_data = np.concatenate(train_data)\n",
    "    test_data = np.concatenate(test_data)\n",
    "\n",
    "    print('Created:', train_data.shape, test_data.shape, time.time()-start)\n",
    "    predictions = trainer(train_data, test_data)\n",
    "    returns = simulate(test_data, predictions)\n",
    "\n",
    "    with open(f\"{result_folder}/predictions-{test_year}.pickle\", 'wb') as handle:\n",
    "        pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    returns.to_csv(f\"{result_folder}/avg_daily_rets-{test_year}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
